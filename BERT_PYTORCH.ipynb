{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT PYTORCH",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b964005b3f614eccb654cc696841ad42": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d6f70030b71f4257b4aefa59076dd5e4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b3d82aac5c7c48d9a86205d17cdde131",
              "IPY_MODEL_a1e8b54a121446908a77b0f1f49d4d06"
            ]
          }
        },
        "d6f70030b71f4257b4aefa59076dd5e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3d82aac5c7c48d9a86205d17cdde131": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a76bc89772064be2b7e37e19f2c8e982",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_31ff2ccec33e401dbc0235e241e1f6f9"
          }
        },
        "a1e8b54a121446908a77b0f1f49d4d06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_345943f67d7c4edd9e2659b65a0b15ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 1.54kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e81a75c0100944b1ae68551e6104e156"
          }
        },
        "a76bc89772064be2b7e37e19f2c8e982": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "31ff2ccec33e401dbc0235e241e1f6f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "345943f67d7c4edd9e2659b65a0b15ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e81a75c0100944b1ae68551e6104e156": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8b8a891facfc489db513d548c3e6482d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_448b5cfd2ec64a67b0dafab738e1a442",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e53a8404535d422d997ec1ede61f6f64",
              "IPY_MODEL_008d845113324961a246da6a80966169"
            ]
          }
        },
        "448b5cfd2ec64a67b0dafab738e1a442": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e53a8404535d422d997ec1ede61f6f64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b217a76cc2174926abe2ce6dc655a4f6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f3d9ab2b9ebd423cb35c9e72172a772d"
          }
        },
        "008d845113324961a246da6a80966169": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4b89f0802de409ebf58f2eda04318eb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:32&lt;00:00, 13.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ccbf074d808a4c6da2820a92a7fb92cc"
          }
        },
        "b217a76cc2174926abe2ce6dc655a4f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f3d9ab2b9ebd423cb35c9e72172a772d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4b89f0802de409ebf58f2eda04318eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ccbf074d808a4c6da2820a92a7fb92cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ru7fvhNQ0RoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9jD-S98gmUp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h7cKcUeguy2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1930d717-0118-4ff3-dc22-a5b56231a3a3"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x3TDuM8gwlg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/NLP/BERT')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrNnmalCn8Sc",
        "colab_type": "text"
      },
      "source": [
        "#import data from kaggle on Google Colab by using Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICLSQJhag4DH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6kn5D-ihHOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "42025377-3201-4ddb-803f-7780c097b529"
      },
      "source": [
        "!pip install -q kaggle-cli "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 81kB 3.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.3MB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 49.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 49.1MB/s \n",
            "\u001b[?25h  Building wheel for kaggle-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkOlhiikhWfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c1329c78-b1ed-4769-b3fb-4eaf074b7022"
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymoBbZQnoCKB",
        "colab_type": "text"
      },
      "source": [
        "#downloading data from kaggle competition to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EatBnPZXiQWl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "0bb3d14b-4d42-485f-bc1a-1d74b35553d1"
      },
      "source": [
        "\n",
        "!kaggle competitions download -c twitter-sentiment-analysis2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content/drive/My Drive/Colab Notebooks/NLP/BERT\n",
            " 82% 9.00M/11.0M [00:00<00:00, 24.9MB/s]\n",
            "100% 11.0M/11.0M [00:00<00:00, 24.7MB/s]\n",
            "Downloading train.csv.zip to /content/drive/My Drive/Colab Notebooks/NLP/BERT\n",
            "  0% 0.00/3.67M [00:00<?, ?B/s]\n",
            "100% 3.67M/3.67M [00:00<00:00, 122MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txylbh59j5Uu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "507fdf1d-0d4b-400a-a2e1-0b1ce359bdcd"
      },
      "source": [
        "!unzip train.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpMgWjFvoLZC",
        "colab_type": "text"
      },
      "source": [
        "#Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2kAcIBDlvNl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "c75ef276-bcf6-4f30-e939-3d09d0afc9ee"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ow2MGD0mQn-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=pd.read_csv('train.csv',encoding='latin-1',header=None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0X0rDSIWWwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3f096d2a-1662-4ea7-bfcb-24f1db42826e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ItemID</td>\n",
              "      <td>Sentiment</td>\n",
              "      <td>SentimentText</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0          1                                                  2\n",
              "0  ItemID  Sentiment                                      SentimentText\n",
              "1       1          0                       is so sad for my APL frie...\n",
              "2       2          0                     I missed the New Moon trail...\n",
              "3       3          1                            omg its already 7:30 :O\n",
              "4       4          0            .. Omgaga. Im sooo  im gunna CRy. I'..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtYOwmovoTNR",
        "colab_type": "text"
      },
      "source": [
        "#Adding some data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xoq6F6WmhkY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[2][0]='I am not feeling good here.'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqucDAtc2tQJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df[1][0]='0'\n",
        "df[0][0]=0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LefMwZxFmkaV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "3728d049-d917-48b1-c67c-647ee3c9f8aa"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I am not feeling good here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1                                                  2\n",
              "0  0  0                        I am not feeling good here.\n",
              "1  1  0                       is so sad for my APL frie...\n",
              "2  2  0                     I missed the New Moon trail...\n",
              "3  3  1                            omg its already 7:30 :O\n",
              "4  4  0            .. Omgaga. Im sooo  im gunna CRy. I'..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4noHpgomnRX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df1=df.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YJoey5bnbfo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.columns=['Id','Sentiment','Tweet_text']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHoWFR18nrsz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "725d08b8-eee7-490a-c56b-0f49d9320115"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I am not feeling good here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Id Sentiment                                         Tweet_text\n",
              "0  0         0                        I am not feeling good here.\n",
              "1  1         0                       is so sad for my APL frie...\n",
              "2  2         0                     I missed the New Moon trail...\n",
              "3  3         1                            omg its already 7:30 :O\n",
              "4  4         0            .. Omgaga. Im sooo  im gunna CRy. I'..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvyw_1vIo8Iz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "75c6505e-3a54-4a4c-e31f-0b4c9065d49c"
      },
      "source": [
        "df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99990 entries, 0 to 99989\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Id          99990 non-null  object\n",
            " 1   Sentiment   99990 non-null  object\n",
            " 2   Tweet_text  99990 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 2.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX_QZ0dRpOOY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "2ada96cd-28fe-479f-87f1-a3ad8b1f55ff"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I am not feeling good here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Id Sentiment                                         Tweet_text\n",
              "0  0         0                        I am not feeling good here.\n",
              "1  1         0                       is so sad for my APL frie...\n",
              "2  2         0                     I missed the New Moon trail...\n",
              "3  3         1                            omg its already 7:30 :O\n",
              "4  4         0            .. Omgaga. Im sooo  im gunna CRy. I'..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9ZQsAMkqbYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.drop('Id',inplace=True,axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LmXPM37iqhZe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "1908d3a2-61d1-49f4-97c7-5e1145b29841"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>I am not feeling good here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Sentiment                                         Tweet_text\n",
              "0         0                        I am not feeling good here.\n",
              "1         0                       is so sad for my APL frie...\n",
              "2         0                     I missed the New Moon trail...\n",
              "3         1                            omg its already 7:30 :O\n",
              "4         0            .. Omgaga. Im sooo  im gunna CRy. I'..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nibwkxtdqnlW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d1731741-bda9-4762-d7d4-12b60ba8d911"
      },
      "source": [
        "df.columns"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Sentiment', 'Tweet_text'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oABLty8LFpSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Sentiment']=df['Sentiment'].apply(int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gABYo1YvFpO8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f7d3c381-df56-49ac-be8a-953b98c87919"
      },
      "source": [
        "df['Sentiment'][0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BVrhvppqrCk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X=df['Tweet_text'].values\n",
        "y=df['Sentiment'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62C9Aswjq1EH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y8yNThJq2NJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val =train_test_split(X, y, test_size=0.1, random_state=101)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrdc9a3FzYAw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV3HyAYBrJKU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "90fb2967-71eb-47ae-c51d-356f08d42016"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "Device name: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03Ad26cJzYzG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "433cb480-48a0-4897-9b00-38a2839f6b82"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.0.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc1 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWUYeUN0zt1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def text_preprocessing(text):\n",
        "    \n",
        "    \n",
        "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
        "\n",
        "    \n",
        "    text = re.sub(r'&amp;', '&', text)\n",
        "\n",
        "    \n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "\n",
        "    return text"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqtavnglz29G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "\n",
        "\n",
        "def preprocessing_for_bert(data):\n",
        "\n",
        "    input_ids = []\n",
        "    attention_masks = []\n",
        "\n",
        "    for sent in data:\n",
        "\n",
        "        encoded_sent = tokenizer.encode_plus(\n",
        "            text=text_preprocessing(sent),  \n",
        "            add_special_tokens=True,        \n",
        "            max_length=MAX_LEN,                 \n",
        "            pad_to_max_length=True,            \n",
        "            return_attention_mask=True ,\n",
        "            truncation=True     \n",
        "            )\n",
        "        \n",
        "        \n",
        "        input_ids.append(encoded_sent.get('input_ids'))\n",
        "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
        "\n",
        "    input_ids = torch.tensor(input_ids)\n",
        "    attention_masks = torch.tensor(attention_masks)\n",
        "\n",
        "    return input_ids, attention_masks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkX7_p-Z07hF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b57bc071-58f3-4f66-d1fb-e3359e9d7a56"
      },
      "source": [
        "\n",
        "all_tweets = df.Tweet_text.values\n",
        "\n",
        "\n",
        "encoded_tweets = [tokenizer.encode(sent, add_special_tokens=True) for sent in all_tweets]\n",
        "\n",
        "max_len = max([len(sent) for sent in encoded_tweets])\n",
        "print('Max length: ', max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max length:  316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLrqGCf91kA7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "b9e28187-8c41-40c3-8883-d10e3ef1be17"
      },
      "source": [
        "\n",
        "MAX_LEN = 64\n",
        "import re\n",
        "\n",
        "\n",
        "token_ids = list(preprocessing_for_bert([X[0]])[0].squeeze().numpy())\n",
        "print('Original: ', X[0])\n",
        "print('Token IDs: ', token_ids)\n",
        "\n",
        "\n",
        "print('Tokenizing data...')\n",
        "train_inputs, train_masks = preprocessing_for_bert(X_train)\n",
        "val_inputs, val_masks = preprocessing_for_bert(X_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  I am not feeling good here.\n",
            "Token IDs:  [101, 1045, 2572, 2025, 3110, 2204, 2182, 1012, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Tokenizing data...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQs_C17P13SN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "\n",
        "train_labels = torch.tensor(y_train)\n",
        "val_labels = torch.tensor(y_val)\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQmrWJf8FeHD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "794ea7ee-1f94-40dd-b08a-3ccb4b557cf1"
      },
      "source": [
        "%%time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import BertModel\n",
        "\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, freeze_bert=False):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "       \n",
        "        D_in, H, D_out = 768, 50, 2\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(D_in, H),\n",
        "            nn.ReLU(),\n",
        "           \n",
        "            nn.Linear(H, D_out)\n",
        "        )\n",
        "\n",
        "        if freeze_bert:\n",
        "            for param in self.bert.parameters():\n",
        "                param.requires_grad = False\n",
        "        \n",
        "    def forward(self, input_ids, attention_mask):\n",
        "       \n",
        "       \n",
        "        outputs = self.bert(input_ids=input_ids,\n",
        "                            attention_mask=attention_mask)\n",
        "        \n",
        "       \n",
        "        last_hidden_state_cls = outputs[0][:, 0, :]\n",
        "\n",
        "       \n",
        "        logits = self.classifier(last_hidden_state_cls)\n",
        "\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 46 µs, sys: 1e+03 ns, total: 47 µs\n",
            "Wall time: 49.8 µs\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZfdLAB2pGckv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "def initialize_model(epochs=4):\n",
        " \n",
        "    bert_classifier = BertClassifier(freeze_bert=False)\n",
        "\n",
        "    \n",
        "    bert_classifier.to(device)\n",
        "\n",
        "\n",
        "    optimizer = AdamW(bert_classifier.parameters(),\n",
        "                      lr=5e-5,    \n",
        "                      eps=1e-8   \n",
        "                      )\n",
        "   \n",
        "    total_steps = len(train_dataloader) * epochs\n",
        "\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
        "                                                num_warmup_steps=0, \n",
        "                                                num_training_steps=total_steps)\n",
        "    return bert_classifier, optimizer, scheduler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9xLIJzBGhIK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import random\n",
        "import time\n",
        "\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\n",
        "    \"\"\"\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader=None, epochs=4, evaluation=False):\n",
        "    \"\"\"Train the BertClassifier model.\n",
        "    \"\"\"\n",
        "    \n",
        "    print(\"Start training...\\n\")\n",
        "    for epoch_i in range(epochs):\n",
        "       \n",
        "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {'Val Acc':^9} | {'Elapsed':^9}\")\n",
        "        print(\"-\"*70)\n",
        "\n",
        "        \n",
        "        t0_epoch, t0_batch = time.time(), time.time()\n",
        "\n",
        "        \n",
        "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
        "\n",
        "        \n",
        "        model.train()\n",
        "\n",
        "        \n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            batch_counts +=1\n",
        "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "            \n",
        "            model.zero_grad()\n",
        "\n",
        "           \n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "            \n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            batch_loss += loss.item()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            \n",
        "            loss.backward()\n",
        "\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "            \n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            \n",
        "            if (step % 20 == 0 and step != 0) or (step == len(train_dataloader) - 1):\n",
        "               \n",
        "                time_elapsed = time.time() - t0_batch\n",
        "\n",
        "                \n",
        "                print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
        "\n",
        "                \n",
        "                batch_loss, batch_counts = 0, 0\n",
        "                t0_batch = time.time()\n",
        "\n",
        "        \n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        print(\"-\"*70)\n",
        "        \n",
        "        if evaluation == True:\n",
        "           \n",
        "            val_loss, val_accuracy = evaluate(model, val_dataloader)\n",
        "\n",
        "           \n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            \n",
        "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {time_elapsed:^9.2f}\")\n",
        "            print(\"-\"*70)\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    print(\"Training complete!\")\n",
        "\n",
        "\n",
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's performance\n",
        "    on our validation set.\n",
        "    \"\"\"\n",
        "    \n",
        "    model.eval()\n",
        "\n",
        "    \n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "\n",
        "    \n",
        "    for batch in val_dataloader:\n",
        "        \n",
        "        b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids, b_attn_mask)\n",
        "\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "\n",
        "    return val_loss, val_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQKX5sXkGrrM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b964005b3f614eccb654cc696841ad42",
            "d6f70030b71f4257b4aefa59076dd5e4",
            "b3d82aac5c7c48d9a86205d17cdde131",
            "a1e8b54a121446908a77b0f1f49d4d06",
            "a76bc89772064be2b7e37e19f2c8e982",
            "31ff2ccec33e401dbc0235e241e1f6f9",
            "345943f67d7c4edd9e2659b65a0b15ed",
            "e81a75c0100944b1ae68551e6104e156",
            "8b8a891facfc489db513d548c3e6482d",
            "448b5cfd2ec64a67b0dafab738e1a442",
            "e53a8404535d422d997ec1ede61f6f64",
            "008d845113324961a246da6a80966169",
            "b217a76cc2174926abe2ce6dc655a4f6",
            "f3d9ab2b9ebd423cb35c9e72172a772d",
            "b4b89f0802de409ebf58f2eda04318eb",
            "ccbf074d808a4c6da2820a92a7fb92cc"
          ]
        },
        "outputId": "cb0f7342-998a-40e8-fc76-0c25f607a547"
      },
      "source": [
        "set_seed(42)    \n",
        "bert_classifier, optimizer, scheduler = initialize_model(epochs=2)\n",
        "train(bert_classifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b964005b3f614eccb654cc696841ad42",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8b8a891facfc489db513d548c3e6482d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Start training...\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   1    |   20    |   0.661556   |     -      |     -     |   7.13   \n",
            "   1    |   40    |   0.536703   |     -      |     -     |   6.65   \n",
            "   1    |   60    |   0.530981   |     -      |     -     |   6.65   \n",
            "   1    |   80    |   0.488778   |     -      |     -     |   6.68   \n",
            "   1    |   100   |   0.467077   |     -      |     -     |   6.73   \n",
            "   1    |   120   |   0.453356   |     -      |     -     |   6.82   \n",
            "   1    |   140   |   0.453102   |     -      |     -     |   6.87   \n",
            "   1    |   160   |   0.513905   |     -      |     -     |   6.90   \n",
            "   1    |   180   |   0.390171   |     -      |     -     |   6.98   \n",
            "   1    |   200   |   0.478004   |     -      |     -     |   7.02   \n",
            "   1    |   220   |   0.481195   |     -      |     -     |   7.09   \n",
            "   1    |   240   |   0.494547   |     -      |     -     |   7.17   \n",
            "   1    |   260   |   0.439239   |     -      |     -     |   7.24   \n",
            "   1    |   280   |   0.475596   |     -      |     -     |   7.31   \n",
            "   1    |   300   |   0.463463   |     -      |     -     |   7.39   \n",
            "   1    |   320   |   0.418500   |     -      |     -     |   7.47   \n",
            "   1    |   340   |   0.428154   |     -      |     -     |   7.53   \n",
            "   1    |   360   |   0.396169   |     -      |     -     |   7.51   \n",
            "   1    |   380   |   0.443548   |     -      |     -     |   7.42   \n",
            "   1    |   400   |   0.440090   |     -      |     -     |   7.38   \n",
            "   1    |   420   |   0.440284   |     -      |     -     |   7.32   \n",
            "   1    |   440   |   0.432631   |     -      |     -     |   7.33   \n",
            "   1    |   460   |   0.425885   |     -      |     -     |   7.33   \n",
            "   1    |   480   |   0.430131   |     -      |     -     |   7.35   \n",
            "   1    |   500   |   0.427674   |     -      |     -     |   7.33   \n",
            "   1    |   520   |   0.384271   |     -      |     -     |   7.33   \n",
            "   1    |   540   |   0.450371   |     -      |     -     |   7.34   \n",
            "   1    |   560   |   0.480722   |     -      |     -     |   7.36   \n",
            "   1    |   580   |   0.393066   |     -      |     -     |   7.38   \n",
            "   1    |   600   |   0.445453   |     -      |     -     |   7.38   \n",
            "   1    |   620   |   0.428782   |     -      |     -     |   7.38   \n",
            "   1    |   640   |   0.442705   |     -      |     -     |   7.37   \n",
            "   1    |   660   |   0.461164   |     -      |     -     |   7.38   \n",
            "   1    |   680   |   0.422156   |     -      |     -     |   7.37   \n",
            "   1    |   700   |   0.415305   |     -      |     -     |   7.38   \n",
            "   1    |   720   |   0.425372   |     -      |     -     |   7.39   \n",
            "   1    |   740   |   0.388899   |     -      |     -     |   7.40   \n",
            "   1    |   760   |   0.410110   |     -      |     -     |   7.39   \n",
            "   1    |   780   |   0.414760   |     -      |     -     |   7.35   \n",
            "   1    |   800   |   0.427958   |     -      |     -     |   7.31   \n",
            "   1    |   820   |   0.424378   |     -      |     -     |   7.33   \n",
            "   1    |   840   |   0.357830   |     -      |     -     |   7.35   \n",
            "   1    |   860   |   0.439270   |     -      |     -     |   7.36   \n",
            "   1    |   880   |   0.391356   |     -      |     -     |   7.36   \n",
            "   1    |   900   |   0.429174   |     -      |     -     |   7.38   \n",
            "   1    |   920   |   0.408017   |     -      |     -     |   7.38   \n",
            "   1    |   940   |   0.412543   |     -      |     -     |   7.38   \n",
            "   1    |   960   |   0.447771   |     -      |     -     |   7.37   \n",
            "   1    |   980   |   0.452547   |     -      |     -     |   7.41   \n",
            "   1    |  1000   |   0.427086   |     -      |     -     |   7.41   \n",
            "   1    |  1020   |   0.429657   |     -      |     -     |   7.39   \n",
            "   1    |  1040   |   0.396838   |     -      |     -     |   7.35   \n",
            "   1    |  1060   |   0.397841   |     -      |     -     |   7.30   \n",
            "   1    |  1080   |   0.437507   |     -      |     -     |   7.29   \n",
            "   1    |  1100   |   0.416620   |     -      |     -     |   7.30   \n",
            "   1    |  1120   |   0.402570   |     -      |     -     |   7.34   \n",
            "   1    |  1140   |   0.413595   |     -      |     -     |   7.36   \n",
            "   1    |  1160   |   0.411369   |     -      |     -     |   7.39   \n",
            "   1    |  1180   |   0.399028   |     -      |     -     |   7.41   \n",
            "   1    |  1200   |   0.371894   |     -      |     -     |   7.40   \n",
            "   1    |  1220   |   0.419881   |     -      |     -     |   7.36   \n",
            "   1    |  1240   |   0.427639   |     -      |     -     |   7.37   \n",
            "   1    |  1260   |   0.416635   |     -      |     -     |   7.40   \n",
            "   1    |  1280   |   0.383496   |     -      |     -     |   7.39   \n",
            "   1    |  1300   |   0.384203   |     -      |     -     |   7.37   \n",
            "   1    |  1320   |   0.422266   |     -      |     -     |   7.35   \n",
            "   1    |  1340   |   0.412479   |     -      |     -     |   7.33   \n",
            "   1    |  1360   |   0.346810   |     -      |     -     |   7.32   \n",
            "   1    |  1380   |   0.435875   |     -      |     -     |   7.35   \n",
            "   1    |  1400   |   0.430933   |     -      |     -     |   7.34   \n",
            "   1    |  1420   |   0.403653   |     -      |     -     |   7.37   \n",
            "   1    |  1440   |   0.435370   |     -      |     -     |   7.36   \n",
            "   1    |  1460   |   0.412544   |     -      |     -     |   7.37   \n",
            "   1    |  1480   |   0.420222   |     -      |     -     |   7.36   \n",
            "   1    |  1500   |   0.399279   |     -      |     -     |   7.37   \n",
            "   1    |  1520   |   0.382205   |     -      |     -     |   7.39   \n",
            "   1    |  1540   |   0.387361   |     -      |     -     |   7.41   \n",
            "   1    |  1560   |   0.409045   |     -      |     -     |   7.38   \n",
            "   1    |  1580   |   0.406836   |     -      |     -     |   7.35   \n",
            "   1    |  1600   |   0.412986   |     -      |     -     |   7.33   \n",
            "   1    |  1620   |   0.408714   |     -      |     -     |   7.31   \n",
            "   1    |  1640   |   0.388169   |     -      |     -     |   7.33   \n",
            "   1    |  1660   |   0.421491   |     -      |     -     |   7.36   \n",
            "   1    |  1680   |   0.397910   |     -      |     -     |   7.38   \n",
            "   1    |  1700   |   0.387818   |     -      |     -     |   7.38   \n",
            "   1    |  1720   |   0.426581   |     -      |     -     |   7.40   \n",
            "   1    |  1740   |   0.399299   |     -      |     -     |   7.39   \n",
            "   1    |  1760   |   0.387129   |     -      |     -     |   7.37   \n",
            "   1    |  1780   |   0.397090   |     -      |     -     |   7.38   \n",
            "   1    |  1800   |   0.390472   |     -      |     -     |   7.40   \n",
            "   1    |  1820   |   0.426647   |     -      |     -     |   7.40   \n",
            "   1    |  1840   |   0.423214   |     -      |     -     |   7.35   \n",
            "   1    |  1860   |   0.349707   |     -      |     -     |   7.33   \n",
            "   1    |  1880   |   0.425274   |     -      |     -     |   7.31   \n",
            "   1    |  1900   |   0.416140   |     -      |     -     |   7.35   \n",
            "   1    |  1920   |   0.368488   |     -      |     -     |   7.36   \n",
            "   1    |  1940   |   0.433562   |     -      |     -     |   7.38   \n",
            "   1    |  1960   |   0.392742   |     -      |     -     |   7.38   \n",
            "   1    |  1980   |   0.426212   |     -      |     -     |   7.40   \n",
            "   1    |  2000   |   0.415641   |     -      |     -     |   7.40   \n",
            "   1    |  2020   |   0.382455   |     -      |     -     |   7.38   \n",
            "   1    |  2040   |   0.428215   |     -      |     -     |   7.39   \n",
            "   1    |  2060   |   0.386566   |     -      |     -     |   7.39   \n",
            "   1    |  2080   |   0.362368   |     -      |     -     |   7.40   \n",
            "   1    |  2100   |   0.378735   |     -      |     -     |   7.37   \n",
            "   1    |  2120   |   0.386572   |     -      |     -     |   7.34   \n",
            "   1    |  2140   |   0.375181   |     -      |     -     |   7.32   \n",
            "   1    |  2160   |   0.431490   |     -      |     -     |   7.32   \n",
            "   1    |  2180   |   0.415374   |     -      |     -     |   7.34   \n",
            "   1    |  2200   |   0.422628   |     -      |     -     |   7.37   \n",
            "   1    |  2220   |   0.395909   |     -      |     -     |   7.39   \n",
            "   1    |  2240   |   0.422318   |     -      |     -     |   7.39   \n",
            "   1    |  2260   |   0.382917   |     -      |     -     |   7.38   \n",
            "   1    |  2280   |   0.389197   |     -      |     -     |   7.38   \n",
            "   1    |  2300   |   0.412387   |     -      |     -     |   7.39   \n",
            "   1    |  2320   |   0.393061   |     -      |     -     |   7.39   \n",
            "   1    |  2340   |   0.394983   |     -      |     -     |   7.39   \n",
            "   1    |  2360   |   0.409856   |     -      |     -     |   7.38   \n",
            "   1    |  2380   |   0.384827   |     -      |     -     |   7.34   \n",
            "   1    |  2400   |   0.393158   |     -      |     -     |   7.32   \n",
            "   1    |  2420   |   0.368046   |     -      |     -     |   7.33   \n",
            "   1    |  2440   |   0.420830   |     -      |     -     |   7.34   \n",
            "   1    |  2460   |   0.378610   |     -      |     -     |   7.37   \n",
            "   1    |  2480   |   0.391118   |     -      |     -     |   7.37   \n",
            "   1    |  2500   |   0.346131   |     -      |     -     |   7.40   \n",
            "   1    |  2520   |   0.369085   |     -      |     -     |   7.39   \n",
            "   1    |  2540   |   0.354592   |     -      |     -     |   7.38   \n",
            "   1    |  2560   |   0.375566   |     -      |     -     |   7.39   \n",
            "   1    |  2580   |   0.366749   |     -      |     -     |   7.38   \n",
            "   1    |  2600   |   0.381508   |     -      |     -     |   7.40   \n",
            "   1    |  2620   |   0.392819   |     -      |     -     |   7.40   \n",
            "   1    |  2640   |   0.363650   |     -      |     -     |   7.37   \n",
            "   1    |  2660   |   0.432220   |     -      |     -     |   7.33   \n",
            "   1    |  2680   |   0.397655   |     -      |     -     |   7.32   \n",
            "   1    |  2700   |   0.432338   |     -      |     -     |   7.34   \n",
            "   1    |  2720   |   0.392080   |     -      |     -     |   7.35   \n",
            "   1    |  2740   |   0.379888   |     -      |     -     |   7.38   \n",
            "   1    |  2760   |   0.406402   |     -      |     -     |   7.37   \n",
            "   1    |  2780   |   0.388051   |     -      |     -     |   7.36   \n",
            "   1    |  2800   |   0.379201   |     -      |     -     |   7.38   \n",
            "   1    |  2812   |   0.362025   |     -      |     -     |   4.18   \n",
            "----------------------------------------------------------------------\n",
            "   1    |    -    |   0.415327   |  0.389073  |   82.33   |  1068.69 \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            " Epoch  |  Batch  |  Train Loss  |  Val Loss  |  Val Acc  |  Elapsed \n",
            "----------------------------------------------------------------------\n",
            "   2    |   20    |   0.285689   |     -      |     -     |   7.66   \n",
            "   2    |   40    |   0.295835   |     -      |     -     |   7.31   \n",
            "   2    |   60    |   0.261492   |     -      |     -     |   7.32   \n",
            "   2    |   80    |   0.273668   |     -      |     -     |   7.35   \n",
            "   2    |   100   |   0.256207   |     -      |     -     |   7.38   \n",
            "   2    |   120   |   0.328144   |     -      |     -     |   7.38   \n",
            "   2    |   140   |   0.285693   |     -      |     -     |   7.40   \n",
            "   2    |   160   |   0.263698   |     -      |     -     |   7.38   \n",
            "   2    |   180   |   0.271167   |     -      |     -     |   7.38   \n",
            "   2    |   200   |   0.256932   |     -      |     -     |   7.39   \n",
            "   2    |   220   |   0.295796   |     -      |     -     |   7.41   \n",
            "   2    |   240   |   0.310552   |     -      |     -     |   7.39   \n",
            "   2    |   260   |   0.253113   |     -      |     -     |   7.37   \n",
            "   2    |   280   |   0.262389   |     -      |     -     |   7.33   \n",
            "   2    |   300   |   0.277187   |     -      |     -     |   7.31   \n",
            "   2    |   320   |   0.252907   |     -      |     -     |   7.34   \n",
            "   2    |   340   |   0.313350   |     -      |     -     |   7.36   \n",
            "   2    |   360   |   0.262669   |     -      |     -     |   7.39   \n",
            "   2    |   380   |   0.258043   |     -      |     -     |   7.39   \n",
            "   2    |   400   |   0.268832   |     -      |     -     |   7.39   \n",
            "   2    |   420   |   0.290890   |     -      |     -     |   7.37   \n",
            "   2    |   440   |   0.287805   |     -      |     -     |   7.39   \n",
            "   2    |   460   |   0.295622   |     -      |     -     |   7.37   \n",
            "   2    |   480   |   0.284687   |     -      |     -     |   7.39   \n",
            "   2    |   500   |   0.268406   |     -      |     -     |   7.40   \n",
            "   2    |   520   |   0.288822   |     -      |     -     |   7.38   \n",
            "   2    |   540   |   0.260052   |     -      |     -     |   7.36   \n",
            "   2    |   560   |   0.299762   |     -      |     -     |   7.33   \n",
            "   2    |   580   |   0.247793   |     -      |     -     |   7.32   \n",
            "   2    |   600   |   0.262591   |     -      |     -     |   7.35   \n",
            "   2    |   620   |   0.278290   |     -      |     -     |   7.35   \n",
            "   2    |   640   |   0.312071   |     -      |     -     |   7.39   \n",
            "   2    |   660   |   0.280619   |     -      |     -     |   7.40   \n",
            "   2    |   680   |   0.281874   |     -      |     -     |   7.38   \n",
            "   2    |   700   |   0.272201   |     -      |     -     |   7.39   \n",
            "   2    |   720   |   0.312039   |     -      |     -     |   7.38   \n",
            "   2    |   740   |   0.229053   |     -      |     -     |   7.41   \n",
            "   2    |   760   |   0.268363   |     -      |     -     |   7.41   \n",
            "   2    |   780   |   0.275661   |     -      |     -     |   7.39   \n",
            "   2    |   800   |   0.279909   |     -      |     -     |   7.36   \n",
            "   2    |   820   |   0.269456   |     -      |     -     |   7.33   \n",
            "   2    |   840   |   0.242985   |     -      |     -     |   7.32   \n",
            "   2    |   860   |   0.250623   |     -      |     -     |   7.34   \n",
            "   2    |   880   |   0.258539   |     -      |     -     |   7.37   \n",
            "   2    |   900   |   0.265892   |     -      |     -     |   7.37   \n",
            "   2    |   920   |   0.276511   |     -      |     -     |   7.39   \n",
            "   2    |   940   |   0.253837   |     -      |     -     |   7.40   \n",
            "   2    |   960   |   0.292967   |     -      |     -     |   7.37   \n",
            "   2    |   980   |   0.259106   |     -      |     -     |   7.39   \n",
            "   2    |  1000   |   0.295841   |     -      |     -     |   7.39   \n",
            "   2    |  1020   |   0.268718   |     -      |     -     |   7.39   \n",
            "   2    |  1040   |   0.253871   |     -      |     -     |   7.41   \n",
            "   2    |  1060   |   0.286505   |     -      |     -     |   7.37   \n",
            "   2    |  1080   |   0.292727   |     -      |     -     |   7.36   \n",
            "   2    |  1100   |   0.237571   |     -      |     -     |   7.34   \n",
            "   2    |  1120   |   0.289776   |     -      |     -     |   7.34   \n",
            "   2    |  1140   |   0.259911   |     -      |     -     |   7.36   \n",
            "   2    |  1160   |   0.304325   |     -      |     -     |   7.37   \n",
            "   2    |  1180   |   0.237569   |     -      |     -     |   7.36   \n",
            "   2    |  1200   |   0.272976   |     -      |     -     |   7.37   \n",
            "   2    |  1220   |   0.248393   |     -      |     -     |   7.37   \n",
            "   2    |  1240   |   0.277241   |     -      |     -     |   7.37   \n",
            "   2    |  1260   |   0.299523   |     -      |     -     |   7.37   \n",
            "   2    |  1280   |   0.318455   |     -      |     -     |   7.40   \n",
            "   2    |  1300   |   0.229650   |     -      |     -     |   7.41   \n",
            "   2    |  1320   |   0.223503   |     -      |     -     |   7.38   \n",
            "   2    |  1340   |   0.285934   |     -      |     -     |   7.34   \n",
            "   2    |  1360   |   0.256910   |     -      |     -     |   7.33   \n",
            "   2    |  1380   |   0.225962   |     -      |     -     |   7.33   \n",
            "   2    |  1400   |   0.263336   |     -      |     -     |   7.35   \n",
            "   2    |  1420   |   0.280652   |     -      |     -     |   7.38   \n",
            "   2    |  1440   |   0.281347   |     -      |     -     |   7.39   \n",
            "   2    |  1460   |   0.239456   |     -      |     -     |   7.39   \n",
            "   2    |  1480   |   0.275380   |     -      |     -     |   7.40   \n",
            "   2    |  1500   |   0.251171   |     -      |     -     |   7.39   \n",
            "   2    |  1520   |   0.279542   |     -      |     -     |   7.39   \n",
            "   2    |  1540   |   0.257409   |     -      |     -     |   7.39   \n",
            "   2    |  1560   |   0.199177   |     -      |     -     |   7.40   \n",
            "   2    |  1580   |   0.263845   |     -      |     -     |   7.40   \n",
            "   2    |  1600   |   0.279281   |     -      |     -     |   7.36   \n",
            "   2    |  1620   |   0.308005   |     -      |     -     |   7.34   \n",
            "   2    |  1640   |   0.270288   |     -      |     -     |   7.30   \n",
            "   2    |  1660   |   0.292853   |     -      |     -     |   7.35   \n",
            "   2    |  1680   |   0.271152   |     -      |     -     |   7.36   \n",
            "   2    |  1700   |   0.268943   |     -      |     -     |   7.38   \n",
            "   2    |  1720   |   0.263365   |     -      |     -     |   7.39   \n",
            "   2    |  1740   |   0.272960   |     -      |     -     |   7.38   \n",
            "   2    |  1760   |   0.235973   |     -      |     -     |   7.39   \n",
            "   2    |  1780   |   0.251562   |     -      |     -     |   7.37   \n",
            "   2    |  1800   |   0.252527   |     -      |     -     |   7.39   \n",
            "   2    |  1820   |   0.255688   |     -      |     -     |   7.40   \n",
            "   2    |  1840   |   0.302119   |     -      |     -     |   7.40   \n",
            "   2    |  1860   |   0.264817   |     -      |     -     |   7.37   \n",
            "   2    |  1880   |   0.252519   |     -      |     -     |   7.33   \n",
            "   2    |  1900   |   0.258554   |     -      |     -     |   7.33   \n",
            "   2    |  1920   |   0.292887   |     -      |     -     |   7.33   \n",
            "   2    |  1940   |   0.273134   |     -      |     -     |   7.35   \n",
            "   2    |  1960   |   0.283439   |     -      |     -     |   7.39   \n",
            "   2    |  1980   |   0.252129   |     -      |     -     |   7.40   \n",
            "   2    |  2000   |   0.273390   |     -      |     -     |   7.41   \n",
            "   2    |  2020   |   0.268880   |     -      |     -     |   7.40   \n",
            "   2    |  2040   |   0.245893   |     -      |     -     |   7.38   \n",
            "   2    |  2060   |   0.266936   |     -      |     -     |   7.39   \n",
            "   2    |  2080   |   0.239513   |     -      |     -     |   7.39   \n",
            "   2    |  2100   |   0.246482   |     -      |     -     |   7.40   \n",
            "   2    |  2120   |   0.267982   |     -      |     -     |   7.39   \n",
            "   2    |  2140   |   0.244285   |     -      |     -     |   7.37   \n",
            "   2    |  2160   |   0.288542   |     -      |     -     |   7.35   \n",
            "   2    |  2180   |   0.320258   |     -      |     -     |   7.35   \n",
            "   2    |  2200   |   0.275581   |     -      |     -     |   7.34   \n",
            "   2    |  2220   |   0.288759   |     -      |     -     |   7.36   \n",
            "   2    |  2240   |   0.277805   |     -      |     -     |   7.36   \n",
            "   2    |  2260   |   0.260304   |     -      |     -     |   7.36   \n",
            "   2    |  2280   |   0.247194   |     -      |     -     |   7.35   \n",
            "   2    |  2300   |   0.240971   |     -      |     -     |   7.36   \n",
            "   2    |  2320   |   0.259595   |     -      |     -     |   7.37   \n",
            "   2    |  2340   |   0.227374   |     -      |     -     |   7.38   \n",
            "   2    |  2360   |   0.220685   |     -      |     -     |   7.41   \n",
            "   2    |  2380   |   0.255584   |     -      |     -     |   7.42   \n",
            "   2    |  2400   |   0.245602   |     -      |     -     |   7.38   \n",
            "   2    |  2420   |   0.256221   |     -      |     -     |   7.34   \n",
            "   2    |  2440   |   0.299177   |     -      |     -     |   7.32   \n",
            "   2    |  2460   |   0.267571   |     -      |     -     |   7.34   \n",
            "   2    |  2480   |   0.272016   |     -      |     -     |   7.36   \n",
            "   2    |  2500   |   0.227920   |     -      |     -     |   7.38   \n",
            "   2    |  2520   |   0.242689   |     -      |     -     |   7.38   \n",
            "   2    |  2540   |   0.287257   |     -      |     -     |   7.40   \n",
            "   2    |  2560   |   0.250277   |     -      |     -     |   7.38   \n",
            "   2    |  2580   |   0.236731   |     -      |     -     |   7.39   \n",
            "   2    |  2600   |   0.247613   |     -      |     -     |   7.38   \n",
            "   2    |  2620   |   0.232538   |     -      |     -     |   7.42   \n",
            "   2    |  2640   |   0.276408   |     -      |     -     |   7.42   \n",
            "   2    |  2660   |   0.310387   |     -      |     -     |   7.38   \n",
            "   2    |  2680   |   0.259771   |     -      |     -     |   7.32   \n",
            "   2    |  2700   |   0.249829   |     -      |     -     |   7.32   \n",
            "   2    |  2720   |   0.223963   |     -      |     -     |   7.35   \n",
            "   2    |  2740   |   0.222073   |     -      |     -     |   7.37   \n",
            "   2    |  2760   |   0.265428   |     -      |     -     |   7.39   \n",
            "   2    |  2780   |   0.261432   |     -      |     -     |   7.40   \n",
            "   2    |  2800   |   0.234318   |     -      |     -     |   7.41   \n",
            "   2    |  2812   |   0.267611   |     -      |     -     |   4.18   \n",
            "----------------------------------------------------------------------\n",
            "   2    |    -    |   0.267321   |  0.424365  |   82.55   |  1075.33 \n",
            "----------------------------------------------------------------------\n",
            "\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEAXL4y1GxDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}