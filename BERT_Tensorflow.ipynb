{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BERT_TENSORFLOW.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9jD-S98gmUp"
      },
      "source": [
        "import os"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_h7cKcUeguy2",
        "outputId": "b559efe6-d1e2-44ac-f4ec-230b5d997351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1x3TDuM8gwlg"
      },
      "source": [
        "os.chdir('/content/drive/My Drive/Colab Notebooks/NLP/BERT')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrNnmalCn8Sc"
      },
      "source": [
        "#import data from kaggle on Google Colab by using Kaggle API"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICLSQJhag4DH"
      },
      "source": [
        "!pip install -q kaggle "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6kn5D-ihHOl",
        "outputId": "42025377-3201-4ddb-803f-7780c097b529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "!pip install -q kaggle-cli "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 81kB 3.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 5.3MB 9.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 112kB 49.9MB/s \n",
            "\u001b[K     |████████████████████████████████| 51kB 6.1MB/s \n",
            "\u001b[K     |████████████████████████████████| 133kB 49.1MB/s \n",
            "\u001b[?25h  Building wheel for kaggle-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XkOlhiikhWfW",
        "outputId": "c1329c78-b1ed-4769-b3fb-4eaf074b7022",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "!ls ~/.kaggle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymoBbZQnoCKB"
      },
      "source": [
        "#downloading data from kaggle competition to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EatBnPZXiQWl",
        "outputId": "0bb3d14b-4d42-485f-bc1a-1d74b35553d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "\n",
        "!kaggle competitions download -c twitter-sentiment-analysis2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.6 / client 1.5.4)\n",
            "Downloading test.csv.zip to /content/drive/My Drive/Colab Notebooks/NLP/BERT\n",
            " 82% 9.00M/11.0M [00:00<00:00, 24.9MB/s]\n",
            "100% 11.0M/11.0M [00:00<00:00, 24.7MB/s]\n",
            "Downloading train.csv.zip to /content/drive/My Drive/Colab Notebooks/NLP/BERT\n",
            "  0% 0.00/3.67M [00:00<?, ?B/s]\n",
            "100% 3.67M/3.67M [00:00<00:00, 122MB/s]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Txylbh59j5Uu",
        "outputId": "507fdf1d-0d4b-400a-a2e1-0b1ce359bdcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip train.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "  inflating: train.csv               \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpMgWjFvoLZC"
      },
      "source": [
        "#Importing Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2kAcIBDlvNl"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ow2MGD0mQn-"
      },
      "source": [
        "df=pd.read_csv('train.csv',encoding='latin-1',header=None)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0X0rDSIWWwy",
        "outputId": "d2f53815-5a58-4484-b644-ecc4b4236502",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ItemID</td>\n",
              "      <td>Sentiment</td>\n",
              "      <td>SentimentText</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        0          1                                                  2\n",
              "0  ItemID  Sentiment                                      SentimentText\n",
              "1       1          0                       is so sad for my APL frie...\n",
              "2       2          0                     I missed the New Moon trail...\n",
              "3       3          1                            omg its already 7:30 :O\n",
              "4       4          0            .. Omgaga. Im sooo  im gunna CRy. I'..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XtYOwmovoTNR"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xoq6F6WmhkY"
      },
      "source": [
        "df[2][0]='I am not feeling good here.'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqucDAtc2tQJ"
      },
      "source": [
        "df[1][0]='0'\n",
        "df[0][0]=0"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LefMwZxFmkaV",
        "outputId": "2fd88a87-d67e-42a2-9f17-c61538f052d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I am not feeling good here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   0  1                                                  2\n",
              "0  0  0                        I am not feeling good here.\n",
              "1  1  0                       is so sad for my APL frie...\n",
              "2  2  0                     I missed the New Moon trail...\n",
              "3  3  1                            omg its already 7:30 :O\n",
              "4  4  0            .. Omgaga. Im sooo  im gunna CRy. I'..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W4noHpgomnRX"
      },
      "source": [
        "df1=df.copy()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YJoey5bnbfo"
      },
      "source": [
        "df.columns=['Id','Sentiment','Tweet_text']"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KHoWFR18nrsz",
        "outputId": "ccc7940a-dd18-48fa-d28a-f740f1653843",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I am not feeling good here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Id Sentiment                                         Tweet_text\n",
              "0  0         0                        I am not feeling good here.\n",
              "1  1         0                       is so sad for my APL frie...\n",
              "2  2         0                     I missed the New Moon trail...\n",
              "3  3         1                            omg its already 7:30 :O\n",
              "4  4         0            .. Omgaga. Im sooo  im gunna CRy. I'..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvyw_1vIo8Iz",
        "outputId": "bf2703aa-9563-4372-b291-1de3b5c6aba6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "df.info()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 99990 entries, 0 to 99989\n",
            "Data columns (total 3 columns):\n",
            " #   Column      Non-Null Count  Dtype \n",
            "---  ------      --------------  ----- \n",
            " 0   Id          99990 non-null  object\n",
            " 1   Sentiment   99990 non-null  object\n",
            " 2   Tweet_text  99990 non-null  object\n",
            "dtypes: object(3)\n",
            "memory usage: 2.3+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OX_QZ0dRpOOY",
        "outputId": "cb54c747-ae7a-489b-b0ec-0c0cd6c5d4ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Id</th>\n",
              "      <th>Sentiment</th>\n",
              "      <th>Tweet_text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I am not feeling good here.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>is so sad for my APL frie...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>I missed the New Moon trail...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>omg its already 7:30 :O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>.. Omgaga. Im sooo  im gunna CRy. I'...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  Id Sentiment                                         Tweet_text\n",
              "0  0         0                        I am not feeling good here.\n",
              "1  1         0                       is so sad for my APL frie...\n",
              "2  2         0                     I missed the New Moon trail...\n",
              "3  3         1                            omg its already 7:30 :O\n",
              "4  4         0            .. Omgaga. Im sooo  im gunna CRy. I'..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5q5NXGUoixX"
      },
      "source": [
        "#Cleaning Text"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKkc3vXdpZvY",
        "outputId": "420e9856-05a5-487e-bef5-dc9170e30e71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.datasets import load_files\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7j5L1gPsgrU"
      },
      "source": [
        "def clean_text(data,col):\n",
        "  corpus=[]\n",
        "  for i in range(len(data[col])):\n",
        "    text=re.sub(r'http\\S+', ' ', data[col][i])\n",
        "    text=text.lower()\n",
        "    text=re.sub(r\"that's\",\"that is\",text)\n",
        "    text = re.sub(r\"there's\",\"there is\",text)\n",
        "    text = re.sub(r\"what's\",\"what is\",text)\n",
        "    text = re.sub(r\"where's\",\"where is\",text)\n",
        "    text = re.sub(r\"it's\",\"it is\",text)\n",
        "    text = re.sub(r\"who's\",\"who is\",text)\n",
        "    text = re.sub(r\"i'm\",\"i am\",text)\n",
        "    text = re.sub(r\"she's\",\"she is\",text)\n",
        "    text = re.sub(r\"he's\",\"he is\",text)\n",
        "    text = re.sub(r\"they're\",\"they are\",text)\n",
        "    text = re.sub(r\"who're\",\"who are\",text)\n",
        "    text = re.sub(r\"ain't\",\"am not\",text)\n",
        "    text = re.sub(r\"wouldn't\",\"would not\",text)\n",
        "    text = re.sub(r\"shouldn't\",\"should not\",text)\n",
        "    text = re.sub(r\"can't\",\"can not\",text)\n",
        "    text = re.sub(r\"couldn't\",\"could not\",text)\n",
        "    text = re.sub(r\"won't\",\"will not\",text)\n",
        "    text=re.sub(r'[@#\\$%&\\*\\(\\)\\<\\>\\?\\!\\;\\'\\\\-\\_\"]',' ',text)\n",
        "    text= re.sub(r'\\W',' ',text)\n",
        "    text=re.sub(r'\\d',' ',text)\n",
        "    text=re.sub(r'^[a-z]\\s',' ',text)\n",
        "    text=re.sub(r'\\s+[a-z]\\s+',' ',text)\n",
        "    text=re.sub(r'\\s+[a-z]$',' ',text)\n",
        "    text=re.sub(r'\\s+',' ',text)\n",
        "    corpus.append(text)\n",
        "  return corpus"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INm2imu3spoS"
      },
      "source": [
        "df['Tweet_text']=clean_text(df,'Tweet_text')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KJMJBKBNtTSw"
      },
      "source": [
        "def remove_stopword(data,col):\n",
        "  corpus=[]\n",
        "  s=set(stopwords.words('english'))\n",
        "  s1=['not','or','no','nor']\n",
        "  for i in s1:\n",
        "    if i in s:\n",
        "      s.remove(i)\n",
        "  for i in range(len(data[col])):\n",
        "    words = nltk.word_tokenize(data[col][i])\n",
        "    word1 = [word for word in words if word not in s]\n",
        "    corpus.append(' '.join(word1))\n",
        "  return corpus\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvUxpNifmObT"
      },
      "source": [
        "df['Tweet_text']=remove_stopword(df,'Tweet_text')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lroykpeGU_Z",
        "outputId": "c168a06c-8293-40c4-c076-2a93ab7be8c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "seq_len = [len(i.split()) for i in df['Tweet_text']]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7faaa2023198>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-YZLD4uggwTD"
      },
      "source": [
        "#Installing BERT for Tensorflow 2.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eUBlHpdILiD",
        "outputId": "1867b841-662d-49ab-dd5b-9d4f7a2b6f94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install bert-for-tf2\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-for-tf2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/c1/015648a2186b25c6de79d15bec40d3d946fcf1dd5067d1c1b28009506486/bert-for-tf2-0.14.6.tar.gz (40kB)\n",
            "\r\u001b[K     |████████                        | 10kB 17.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 30kB 1.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 40kB 1.5MB/s \n",
            "\u001b[?25hCollecting py-params>=0.9.6\n",
            "  Downloading https://files.pythonhosted.org/packages/a4/bf/c1c70d5315a8677310ea10a41cfc41c5970d9b37c31f9c90d4ab98021fd1/py-params-0.9.7.tar.gz\n",
            "Collecting params-flow>=0.8.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a9/95/ff49f5ebd501f142a6f0aaf42bcfd1c192dc54909d1d9eb84ab031d46056/params-flow-0.8.2.tar.gz\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (1.18.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from params-flow>=0.8.0->bert-for-tf2) (4.41.1)\n",
            "Building wheels for collected packages: bert-for-tf2, py-params, params-flow\n",
            "  Building wheel for bert-for-tf2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for bert-for-tf2: filename=bert_for_tf2-0.14.6-cp36-none-any.whl size=30318 sha256=69e8c076009811e09c47e66937b1ca7b5421c798a53e2397913e113ca43ad85a\n",
            "  Stored in directory: /root/.cache/pip/wheels/07/a0/b4/75b0601ebaa41e517a797fe9cea119c789664c8408f8a74ae9\n",
            "  Building wheel for py-params (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-params: filename=py_params-0.9.7-cp36-none-any.whl size=7304 sha256=a09ea4606530656bc3b6e177bea26daa15a334590abca9cbec5047459229c7f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/67/f5/19/b461849a50aefdf4bab47c4756596e82ee2118b8278e5a1980\n",
            "  Building wheel for params-flow (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for params-flow: filename=params_flow-0.8.2-cp36-none-any.whl size=19475 sha256=b226049bc123c069b048469373b4d869336809a9a37f72712b41d11197caa583\n",
            "  Stored in directory: /root/.cache/pip/wheels/08/c8/7f/81c86b9ff2b86e2c477e3914175be03e679e596067dc630c06\n",
            "Successfully built bert-for-tf2 py-params params-flow\n",
            "Installing collected packages: py-params, params-flow, bert-for-tf2\n",
            "Successfully installed bert-for-tf2-0.14.6 params-flow-0.8.2 py-params-0.9.7\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 2.7MB/s \n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.91\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le2jj6mnk8r6"
      },
      "source": [
        "try:\n",
        "    %tensorflow_version 2.x\n",
        "except Exception:\n",
        "    pass"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqpz-Hzbhyd2"
      },
      "source": [
        " tensorflow_hub is a place where you can find all the prebuilt and pretrained models developed in TensorFlow. We will be importing and using a built-in BERT model from TF hub."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZ-Zsd8_lHaT"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "import bert"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3qMgGbQiHrf"
      },
      "source": [
        "#BERT Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c-fYRQ8flKOx"
      },
      "source": [
        "BertTokenizer = bert.bert_tokenization.FullTokenizer\n",
        "bert_layer = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/1\",\n",
        "                            trainable=False)\n",
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = BertTokenizer(vocab_file, lower_case)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-RuBKnPlbHB",
        "outputId": "a754d277-418d-46bd-80f8-ad18f4252c9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.tokenize(\"Stay home Stay safe\")"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stay', 'home', 'stay', 'safe']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1L-uDvVlpN0",
        "outputId": "27ff0ecf-43cf-484e-a07c-27913cafd540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tokenizer.convert_tokens_to_ids(tokenizer.tokenize(\"stay home stay safe\"))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2994, 2188, 2994, 3647]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wz0FnY04lxNv"
      },
      "source": [
        "def tokenize_tweet(text_reviews):\n",
        "    return tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text_reviews))"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnuyGW6PnrUS"
      },
      "source": [
        "tokenized_tweet = [tokenize_tweet(tweet) for tweet in df['Tweet_text']]"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "911DQRGuiv1f"
      },
      "source": [
        "#Prerparing Data For Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1TCt8G1pyq4"
      },
      "source": [
        "tweet_len = [[tweet, df['Sentiment'][i], len(tweet)]\n",
        "                 for i, tweet in enumerate(tokenized_tweet)]"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J96n83vMr2Q-"
      },
      "source": [
        "import random\n",
        "random.shuffle(tweet_len)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eEwRqiv2suoY"
      },
      "source": [
        "tweet_len.sort(key=lambda x: x[2])"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfKIAzJltIhk"
      },
      "source": [
        "sorted_labels = [(tweet_lab[0], tweet_lab[1]) for tweet_lab in tweet_len]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdjB8pOji9C_"
      },
      "source": [
        "Chaning in to TensorFlow 2.0-compliant input dataset shape."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1DMoUPsn7B5"
      },
      "source": [
        "processed_dataset = tf.data.Dataset.from_generator(lambda: sorted_labels, output_types=(tf.int32, tf.int32))"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHr7ZUjajRaa"
      },
      "source": [
        "#Padding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_lqwcHjp6ZS"
      },
      "source": [
        "BATCH_SIZE = 32\n",
        "batched_dataset = processed_dataset.padded_batch(BATCH_SIZE, padded_shapes=((None, ), ()))"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSeGil1YqDoV",
        "outputId": "07cdfee7-02a1-4ea3-b7e5-8313dc668d07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 612
        }
      },
      "source": [
        "next(iter(batched_dataset))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(32, 1), dtype=int32, numpy=\n",
              " array([[   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [   0],\n",
              "        [6289],\n",
              "        [8510],\n",
              "        [3103],\n",
              "        [3407]], dtype=int32)>, <tf.Tensor: shape=(32,), dtype=int32, numpy=\n",
              " array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0,\n",
              "        1, 1, 0, 0, 0, 1, 0, 1, 1, 1], dtype=int32)>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCXQ_qMhqI4h"
      },
      "source": [
        ""
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bJmCk85josv"
      },
      "source": [
        "#Splitting of Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPi6GfP-9A9B",
        "outputId": "dfa9f730-c003-4bb9-dd4b-e7be53b34b6e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "math.ceil(len(sorted_labels) / BATCH_SIZE)//10"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkK0i7g09Syy",
        "outputId": "bae31d38-1925-45f3-de75-01bb9de1b24a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "t2=batched_dataset.take(TEST_BATCHES)\n",
        "t3=batched_dataset.take(TEST_BATCHES)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-45-388b7f608497>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    445\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset length is infinite.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mUNKNOWN\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"dataset length is unknown.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: dataset length is unknown."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5n6mwsb9Svy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qr4QtEWY9Sq0"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gX4Udxcd_Wdf"
      },
      "source": [
        "import math\n",
        "TOTAL_BATCHES = math.ceil(len(sorted_labels) / BATCH_SIZE)\n",
        "TEST_BATCHES = TOTAL_BATCHES // 10\n",
        "batched_dataset.shuffle(TOTAL_BATCHES)\n",
        "test_data = batched_dataset.take(TEST_BATCHES)\n",
        "train_data = batched_dataset.skip(TEST_BATCHES)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q57VJ7VXjxjO"
      },
      "source": [
        "#Creating the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ro4XD54kD6no"
      },
      "source": [
        "class model(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self,\n",
        "                 vocabulary_size,\n",
        "                 embedding_dimensions=128,\n",
        "                 cnn_filters=50,\n",
        "                 dnn_units=512,\n",
        "                 model_output_classes=2,\n",
        "                 dropout_rate=0.1,\n",
        "                 training=False,\n",
        "                 name=\"text_model\"):\n",
        "        super(model, self).__init__(name=name)\n",
        "        \n",
        "        self.embedding = layers.Embedding(vocabulary_size,\n",
        "                                          embedding_dimensions)\n",
        "        self.cnn_layer1 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=2,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer2 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=3,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.cnn_layer3 = layers.Conv1D(filters=cnn_filters,\n",
        "                                        kernel_size=4,\n",
        "                                        padding=\"valid\",\n",
        "                                        activation=\"relu\")\n",
        "        self.pool = layers.GlobalMaxPool1D()\n",
        "        \n",
        "        self.dense_1 = layers.Dense(units=dnn_units, activation=\"relu\")\n",
        "        self.dropout = layers.Dropout(rate=dropout_rate)\n",
        "        if model_output_classes == 2:\n",
        "            self.last_dense = layers.Dense(units=1,\n",
        "                                           activation=\"sigmoid\")\n",
        "        else:\n",
        "            self.last_dense = layers.Dense(units=model_output_classes,\n",
        "                                           activation=\"softmax\")\n",
        "    \n",
        "    def call(self, inputs, training):\n",
        "        l = self.embedding(inputs)\n",
        "        l_1 = self.cnn_layer1(l) \n",
        "        l_1 = self.pool(l_1) \n",
        "        l_2 = self.cnn_layer2(l) \n",
        "        l_2 = self.pool(l_2)\n",
        "        l_3 = self.cnn_layer3(l)\n",
        "        l_3 = self.pool(l_3) \n",
        "        \n",
        "        concatenated = tf.concat([l_1, l_2, l_3], axis=-1)\n",
        "        concatenated = self.dense_1(concatenated)\n",
        "        concatenated = self.dropout(concatenated, training)\n",
        "        model_output = self.last_dense(concatenated)\n",
        "        \n",
        "        return model_output"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gqNQILI5kBdz"
      },
      "source": [
        "parameters of  model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfWN4n2xGFFV"
      },
      "source": [
        "VOCAB_LENGTH = len(tokenizer.vocab)\n",
        "EMB_DIM = 200\n",
        "CNN_FILTERS = 100\n",
        "DNN_UNITS = 256\n",
        "OUTPUT_CLASSES = 2\n",
        "DROPOUT_RATE = 0.2\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6l235A6kGVKC"
      },
      "source": [
        "text_model = model(vocabulary_size=VOCAB_LENGTH,\n",
        "                        embedding_dimensions=EMB_DIM,\n",
        "                        cnn_filters=CNN_FILTERS,\n",
        "                        dnn_units=DNN_UNITS,\n",
        "                        model_output_classes=OUTPUT_CLASSES,\n",
        "                        dropout_rate=DROPOUT_RATE)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGCL7xISGbYu"
      },
      "source": [
        "if OUTPUT_CLASSES == 2:\n",
        "    text_model.compile(loss=\"binary_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"accuracy\"])\n",
        "else:\n",
        "    text_model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "                       optimizer=\"adam\",\n",
        "                       metrics=[\"sparse_categorical_accuracy\"])"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tGcBviyLkNzx"
      },
      "source": [
        "#Fitting of Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z4us2VguGgIo",
        "outputId": "1bcf3ac8-9b5e-4a23-d7ad-847ac6d51cd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "text_model.fit(train_data, epochs=5)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "2813/2813 [==============================] - 217s 77ms/step - loss: 0.5204 - accuracy: 0.7393\n",
            "Epoch 2/5\n",
            "2813/2813 [==============================] - 217s 77ms/step - loss: 0.3758 - accuracy: 0.8322\n",
            "Epoch 3/5\n",
            "2813/2813 [==============================] - 218s 77ms/step - loss: 0.1838 - accuracy: 0.9264\n",
            "Epoch 4/5\n",
            "2813/2813 [==============================] - 218s 78ms/step - loss: 0.1068 - accuracy: 0.9592\n",
            "Epoch 5/5\n",
            "2813/2813 [==============================] - 219s 78ms/step - loss: 0.0823 - accuracy: 0.9688\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faa64084ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIrWd8U4kTmz"
      },
      "source": [
        "#Evalauting Model on Test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qYNoxiVLh2Ko",
        "outputId": "02b7f141-a36d-47cf-dabf-42250cb2aa95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        }
      },
      "source": [
        "results = text_model.evaluate(test_data)\n",
        "print(results)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-0fc0b8d7099d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1377\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'TraceContext'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1378\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1379\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1380\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1381\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    844\u001b[0m               *args, **kwds)\n\u001b[1;32m    845\u001b[0m       \u001b[0;31m# If we did not create any variables the trace we have is good enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_concrete_stateful_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanon_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfn_with_cond\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minner_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0minner_kwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m:  Computed output size would be negative: -1 [input_size: 1, effective_filter_size: 3, stride: 1]\n\t [[node text_model/conv1d_1/conv1d (defined at <ipython-input-78-9922501cfed6>:43) ]] [Op:__inference_test_function_75628]\n\nFunction call stack:\ntest_function\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJjjQ-KYOlOD"
      },
      "source": [
        "sent1='This movie is awesome'\n",
        "token=tokenize_tweet(sent1)\n",
        "input=tf.expand_dims(token,0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ThbYt9QkOlJU"
      },
      "source": [
        "output=text_model(input,training=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irEe5NdXPAaa",
        "outputId": "01f12c31-d328-47c1-e0cc-94e19265139d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "sentiment=np.round(output)\n",
        "if sentiment==0:\n",
        "  print('Sentiment is Negative:',sentiment)\n",
        "elif sentiment==1:\n",
        "  print('Sentiment is Positive:',output)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiment is Positive: tf.Tensor([[0.99997735]], shape=(1, 1), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2C5xbCgTkbYN"
      },
      "source": [
        "#Thank you"
      ]
    }
  ]
}